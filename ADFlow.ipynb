{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import networkx as nx\n",
    "# import clubear as cb\n",
    "import chardet\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import glob\n",
    "\n",
    "warnings.filterwarnings('ignore') # 在整个Python脚本执行期间忽略所有的警告。\n",
    "\n",
    "'''\n",
    "Step 1: Load and Combine Data\n",
    "Adjust the selected_years list in to include the years the user wishes to analyse.\n",
    "对代码增加功能改进：\n",
    "（1）一次性流式读取文件夹中的所有年份，将数据规模扩展至更成熟的大规模数据处理\n",
    "（2）多种编码格式的支持（utf8，iso等等）\n",
    "（3）对于无法识别的编码格式，使用chardet库来自动检测编码格式\n",
    "(4)适当改变object数据类型的格式尝试解决df数据集规模过大导致的内存不足问题（解决完成）\n",
    "'''\n",
    "def load_flight_data(years,path_folder,encodings):\n",
    "    data_frames = []\n",
    "    for year in years:\n",
    "        file_path = f\"{year}.csv\"\n",
    "        file_path_data=os.path.join(path_folder,file_path)\n",
    "        if os.path.exists(file_path_data):\n",
    "            loaded = False\n",
    "            for encoding in encodings:\n",
    "                try:\n",
    "                    #转换数据为unicode编码以及转换分类数据的程序\n",
    "                    # df=pd.read_csv(file_path_data,encoding=encoding,dtype='unicode')\n",
    "                    #convert object data type to category data type\n",
    "                    # for col in df.select_dtypes(include=['object']).columns:\n",
    "                    #     df[col]=df[col].astype('category')\n",
    "                    # data_frames.append(df)\n",
    "                    data_frames.append(pd.read_csv(file_path_data,encoding=encoding))\n",
    "                    print(\"Year {} loaded successfully.\".format(year))\n",
    "                    loaded=True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    #在有出现除编码之外的异常编码时抛出自定义编码异常（但只是在encoding数组里面显示”不是这个编码，而不是显示“是什么错误编码”）\n",
    "                    print(f\"Warning: Failed to load file for year {year} with encoding {encoding}. Error: {e}\")\n",
    "            if not loaded:\n",
    "                #用chardet检测异常编码的编码格式\n",
    "                with open(file_path_data, 'rb') as f:\n",
    "                    result = chardet.detect(f.read())\n",
    "                    detected_encoding = result['encoding']\n",
    "                    print(f\"Error: File for year {year} could not be loaded with provided encodings. Detected encoding: {detected_encoding}\")\n",
    "                    # print(f\"Warning: File for year {year} not found.\")\n",
    "        else:\n",
    "            print(f\"Warning: File for year {year} not found.\")\n",
    "    if data_frames:\n",
    "        combined_data = pd.concat(data_frames, ignore_index=True)\n",
    "        return combined_data\n",
    "    else:\n",
    "        print(\"No data loaded.\")\n",
    "        return pd.DataFrame()\n",
    "    # Return an empty DataFrame if no data is loaded.\n",
    "    # 翻译：如果没有加载数据，则返回一个空的DataFrame。\n",
    "\n",
    "'''\n",
    "修改部分1：将文件修改部署到文件夹的全局文件\n",
    "'''\n",
    "# file_paths = glob.glob('/path/to/csv/files/*.csv')  # 使用glob来获取所有CSV文件的路径\n",
    "# datacombined = [pd.read_csv(file) for file in file_paths]\n",
    "#读取和合并所有年份文件\n",
    "\n",
    "# 合并所有CSV文件的数据\n",
    "# data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Choose the years you want to load.\n",
    "#如何从csv文件中提取对应的年份，并且加入到下面的数组中：\n",
    "current_folder=os.getcwd()\n",
    "source_foder_init='MLDataset'\n",
    "source_foder_path=os.path.join(current_folder,source_foder_init)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "selected_years = [2004,2005]\n",
    "\n",
    "#改进：拼接所有年份\n",
    "# for filename in os.listdir(source_foder_path):\n",
    "#     if filename.endswith('.csv'):\n",
    "#         year = filename.split('.')[0]\n",
    "#         selected_years.append(int(year))\n",
    "        # print(\"Year {} added to the list.\".format(year))\n",
    "        \n",
    "\n",
    "print(\"Selected years: \", selected_years)\n",
    "\n",
    "\n",
    "  # It can be replaced with the desired years.\n",
    "\n",
    "# Load the data for the selected years.\n",
    "#改进：大数据适应性：调整在不同编码方式下的数据读取\n",
    "encodings=['ISO-8859-1','utf-8','GBK','cp1252','ISO-8859-2','utf-16','utf-32',]\n",
    "combined_flight_data = load_flight_data(selected_years,source_foder_path,encodings)\n",
    "\n",
    "\n",
    "# Basic data exploration\n",
    "print(combined_flight_data.shape)\n",
    "combined_flight_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Step 2: Clean Data 此处根据清洗过后的数据集来分析\n",
    "'''\n",
    "# Remove duplicate rows\n",
    "#删除数据列中重复出现的行（但是不是有可能并没有必要，因为此类航空数据可能重复的行不多）\n",
    "combined_flight_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "#进行最简单处理，将整个数据集中缺失值替换成0.。\n",
    "cleaned_combined_flight_data = combined_flight_data.fillna(0)\n",
    "\n",
    "# Replace airline codes with full names\n",
    "'''\n",
    "把列中的uniquecarrier换成全称。\n",
    "'''\n",
    "airline_names = {\n",
    "    'UA': 'United Airlines', 'US': 'United States Airways', 'WN': 'Southwest Airlines',\n",
    "    'NW': 'Northwest Airlines', 'OH': 'PSA Airlines', 'OO': 'SkyWest Airlines',\n",
    "    'XE': 'Expressjet Airlines', 'TZ': 'Air Tazania Airlines', 'DL': 'Delta Airlines',\n",
    "    'EV': 'Atlantic Southeast Airlines', 'FL': 'Florida Airlines', 'HA': 'Hawaiian Airlines',\n",
    "    'HP': 'America West Airlines', 'MQ': 'Envoy Airlines', 'AA': 'American Airlines',\n",
    "    'AS': 'Alaska Airlines', 'B6': 'JetBlue Airways', 'CO': 'Continental Airlines',\n",
    "    'DH': 'Indepedence Airlines', 'F9': 'Frontier Airlines'\n",
    "}\n",
    "cleaned_combined_flight_data['UniqueCarrier'].replace(airline_names, inplace=True)\n",
    "\n",
    "# Export cleaned data to CSV\n",
    "cleaned_combined_flight_data.to_csv('cleaned_combined_flight_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import networkx as nx\n",
    "import chardet\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "'''\n",
    "Step 3: Feature Engineering\n",
    "'''\n",
    "# Create new features\n",
    "#这里的做法大概是想要将设计时间这一列从12h制转换为24h制，以便于更好的分析数据。然后将24h的数据添加到最后一行里\n",
    "\n",
    "cleaned_combined_flight_data=pd.read_csv('cleaned_combined_flight_data.csv')\n",
    "\n",
    "\n",
    "cleaned_combined_flight_data['DepTime'] = cleaned_combined_flight_data['DepTime'].astype(float)\n",
    "bins = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400]\n",
    "labels = [\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\", \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\", \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"]\n",
    "cleaned_combined_flight_data['24HoursTime'] = pd.cut(cleaned_combined_flight_data['DepTime'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# show1=cleaned_combined_flight_data['24HoursTime'].head(5)\n",
    "\n",
    "# print(show1)\n",
    "\n",
    "#注意此处bins的标签数必须比labels多一个。因为在这里的数据区分中bin实际上才是实际的区间划分的函数。\n",
    "#而labels只是用来标注每个区间的标签而已。所以一个label往往夹在bin的两个区间之间作为标签。所以这么看来bin至少要比label多一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum', 'TailNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Origin', 'Dest', 'Distance', 'TaxiIn', 'TaxiOut', 'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', '24HoursTime']\n",
      "['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum', 'TailNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'Origin', 'Dest', 'Distance', 'TaxiIn', 'TaxiOut', 'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', '24HoursTime']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Step 4: Train Machine Learning Models\n",
    "改进：（1）修正了这里分类数据独热化，再选取独热化的行作为特征的流程，使其能正确运行\n",
    "'''\n",
    "# Prepare data for training\n",
    "#此处遇到的问题是标签被之前转换的变量变成了多个列变量。所以可能需要在这里用转换分类变量的方式把标签变量转换为分类变量次啊能get\n",
    "#dummies训练了。\n",
    "#那么由于feature的性质问题，feature在这里干脆定义为反选\n",
    "#可能这里只能用传统的数据筛选的方法来选择特征了。即挑出特定几列作为target或者drop特定几列。\n",
    "\n",
    "# 先将数据列中的object数据类型转换为category数据类型\n",
    "# for col in cleaned_combined_flight_data.select_dtypes(include=['object']).columns:\n",
    "#     cleaned_combined_flight_data[col]=cleaned_combined_flight_data[col].astype('category')\n",
    "    \n",
    "print(cleaned_combined_flight_data.columns.tolist())\n",
    "\n",
    "unique_carrier_cols = cleaned_combined_flight_data.filter(like='UniqueCarrier_').columns.tolist()\n",
    "orign_cols = cleaned_combined_flight_data.filter(like='Origin_').columns.tolist()\n",
    "dest_cols = cleaned_combined_flight_data.filter(like='Dest_').columns.tolist()\n",
    "\n",
    "transcols=unique_carrier_cols+orign_cols+dest_cols\n",
    "    \n",
    "# Convert categorical features to numerical values\n",
    "# 相当于将分类数据变成了独热编码的虚拟变量。故这个独热化应该是要先处理的。之后才能是特征选取\n",
    "cleaned_combined_flight_data = pd.get_dummies(cleaned_combined_flight_data, columns=transcols)\n",
    "    \n",
    "# features = ['Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', \n",
    "#             'FlightNum', 'TailNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', \n",
    "#             'ArrDelay', 'DepDelay', 'Distance', 'TaxiIn', 'TaxiOut', 'Cancelled', \n",
    "#             'CancellationCode', 'Diverted', 'CarrierDelay', 'WeatherDelay', 'NASDelay', \n",
    "#             'SecurityDelay', 'LateAircraftDelay','24HoursTime']\n",
    "features=cleaned_combined_flight_data.drop(columns=['DepDelay']).columns.tolist()\n",
    "\n",
    "print(features)\n",
    "# 'UniqueCarrier',\n",
    "# 'Origin', 'Dest',\n",
    "target = 'DepDelay'\n",
    "\n",
    "\n",
    "\n",
    "# print([col for col in cleaned_combined_flight_data.columns])\n",
    "\n",
    "# print(cleaned_combined_flight_data.head())\n",
    "# print(cleaned_combined_flight_data.info())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# feature_columns=unique_carrier_cols+orign_cols+dest_cols\n",
    "# print(feature_columns)\n",
    "\n",
    "# features = cleaned_combined_flight_data[feature_columns]\n",
    "\n",
    "\n",
    "\n",
    "# features=feature_columns+features\n",
    "# print(features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 获取虚拟变量列名\n",
    "# dummy_columns = [col for col in cleaned_combined_flight_data.columns if col.startswith('UniqueCarrier_') or col.startswith('Origin_') or col.startswith('Dest_')]\n",
    "\n",
    "# # 更新 features 列表\n",
    "# features = [feature for feature in features if feature not in ['UniqueCarrier', 'Origin', 'Dest']] + dummy_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'Origin', 'Dest', 'Distance', 'TaxiIn', 'TaxiOut', 'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
      "['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', 'FlightNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'Distance', 'TaxiIn', 'TaxiOut', 'Cancelled', 'Diverted', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'UniqueCarrier_Air Tazania Airlines', 'UniqueCarrier_Alaska Airlines', 'UniqueCarrier_America West Airlines', 'UniqueCarrier_American Airlines', 'UniqueCarrier_Atlantic Southeast Airlines', 'UniqueCarrier_Continental Airlines', 'UniqueCarrier_Delta Airlines', 'UniqueCarrier_Envoy Airlines', 'UniqueCarrier_Expressjet Airlines', 'UniqueCarrier_Florida Airlines', 'UniqueCarrier_Hawaiian Airlines', 'UniqueCarrier_Indepedence Airlines', 'UniqueCarrier_JetBlue Airways', 'UniqueCarrier_Northwest Airlines', 'UniqueCarrier_PSA Airlines', 'UniqueCarrier_SkyWest Airlines', 'UniqueCarrier_Southwest Airlines', 'UniqueCarrier_United Airlines', 'UniqueCarrier_United States Airways', 'Origin_ABE', 'Origin_ABI', 'Origin_ABQ', 'Origin_ABY', 'Origin_ACK', 'Origin_ACT', 'Origin_ACV', 'Origin_ACY', 'Origin_ADK', 'Origin_ADQ', 'Origin_AEX', 'Origin_AGS', 'Origin_AKN', 'Origin_ALB', 'Origin_AMA', 'Origin_ANC', 'Origin_APF', 'Origin_ATL', 'Origin_ATW', 'Origin_AUS', 'Origin_AVL', 'Origin_AVP', 'Origin_AZO', 'Origin_BDL', 'Origin_BET', 'Origin_BFL', 'Origin_BGM', 'Origin_BGR', 'Origin_BHM', 'Origin_BIL', 'Origin_BIS', 'Origin_BMI', 'Origin_BNA', 'Origin_BOI', 'Origin_BOS', 'Origin_BPT', 'Origin_BQK', 'Origin_BQN', 'Origin_BRO', 'Origin_BRW', 'Origin_BTM', 'Origin_BTR', 'Origin_BTV', 'Origin_BUF', 'Origin_BUR', 'Origin_BWI', 'Origin_BZN', 'Origin_CAE', 'Origin_CAK', 'Origin_CDC', 'Origin_CDV', 'Origin_CEC', 'Origin_CHA', 'Origin_CHO', 'Origin_CHS', 'Origin_CIC', 'Origin_CID', 'Origin_CKB', 'Origin_CLD', 'Origin_CLE', 'Origin_CLL', 'Origin_CLT', 'Origin_CMH', 'Origin_CMI', 'Origin_COD', 'Origin_COS', 'Origin_CPR', 'Origin_CRP', 'Origin_CRW', 'Origin_CSG', 'Origin_CVG', 'Origin_CYS', 'Origin_DAB', 'Origin_DAL', 'Origin_DAY', 'Origin_DBQ', 'Origin_DCA', 'Origin_DEN', 'Origin_DFW', 'Origin_DHN', 'Origin_DLG', 'Origin_DLH', 'Origin_DRO', 'Origin_DSM', 'Origin_DTW', 'Origin_DUT', 'Origin_EFD', 'Origin_EGE', 'Origin_EKO', 'Origin_ELP', 'Origin_ERI', 'Origin_EUG', 'Origin_EVV', 'Origin_EWR', 'Origin_EYW', 'Origin_FAI', 'Origin_FAR', 'Origin_FAT', 'Origin_FAY', 'Origin_FCA', 'Origin_FLL', 'Origin_FLO', 'Origin_FMN', 'Origin_FNT', 'Origin_FSD', 'Origin_FSM', 'Origin_FWA', 'Origin_GEG', 'Origin_GFK', 'Origin_GGG', 'Origin_GJT', 'Origin_GNV', 'Origin_GPT', 'Origin_GRB', 'Origin_GRK', 'Origin_GRR', 'Origin_GSO', 'Origin_GSP', 'Origin_GST', 'Origin_GTF', 'Origin_GTR', 'Origin_GUC', 'Origin_HDN', 'Origin_HLN', 'Origin_HNL', 'Origin_HOU', 'Origin_HPN', 'Origin_HRL', 'Origin_HSV', 'Origin_HTS', 'Origin_HVN', 'Origin_IAD', 'Origin_IAH', 'Origin_ICT', 'Origin_IDA', 'Origin_ILE', 'Origin_ILM', 'Origin_IND', 'Origin_IPL', 'Origin_ISP', 'Origin_ITO', 'Origin_IYK', 'Origin_JAC', 'Origin_JAN', 'Origin_JAX', 'Origin_JFK', 'Origin_JNU', 'Origin_KOA', 'Origin_KTN', 'Origin_LAN', 'Origin_LAS', 'Origin_LAW', 'Origin_LAX', 'Origin_LBB', 'Origin_LCH', 'Origin_LEX', 'Origin_LFT', 'Origin_LGA', 'Origin_LGB', 'Origin_LIH', 'Origin_LIT', 'Origin_LNK', 'Origin_LNY', 'Origin_LRD', 'Origin_LSE', 'Origin_LWB', 'Origin_LWS', 'Origin_LYH', 'Origin_MAF', 'Origin_MBS', 'Origin_MCI', 'Origin_MCN', 'Origin_MCO', 'Origin_MDT', 'Origin_MDW', 'Origin_MEI', 'Origin_MEM', 'Origin_MFE', 'Origin_MFR', 'Origin_MGM', 'Origin_MHT', 'Origin_MIA', 'Origin_MKE', 'Origin_MKK', 'Origin_MLB', 'Origin_MLI', 'Origin_MLU', 'Origin_MOB', 'Origin_MOD', 'Origin_MOT', 'Origin_MQT', 'Origin_MRY', 'Origin_MSN', 'Origin_MSO', 'Origin_MSP', 'Origin_MSY', 'Origin_MTJ', 'Origin_MYR', 'Origin_OAK', 'Origin_OGD', 'Origin_OGG', 'Origin_OKC', 'Origin_OMA', 'Origin_OME', 'Origin_ONT', 'Origin_ORD', 'Origin_ORF', 'Origin_OTZ', 'Origin_OXR', 'Origin_PBI', 'Origin_PDX', 'Origin_PFN', 'Origin_PHF', 'Origin_PHL', 'Origin_PHX', 'Origin_PIA', 'Origin_PIE', 'Origin_PIH', 'Origin_PIT', 'Origin_PNS', 'Origin_PSC', 'Origin_PSG', 'Origin_PSP', 'Origin_PUB', 'Origin_PVD', 'Origin_PVU', 'Origin_PWM', 'Origin_RAP', 'Origin_RDD', 'Origin_RDM', 'Origin_RDU', 'Origin_RIC', 'Origin_RNO', 'Origin_ROA', 'Origin_ROC', 'Origin_RST', 'Origin_RSW', 'Origin_SAN', 'Origin_SAT', 'Origin_SAV', 'Origin_SBA', 'Origin_SBN', 'Origin_SBP', 'Origin_SCC', 'Origin_SCE', 'Origin_SDF', 'Origin_SEA', 'Origin_SFO', 'Origin_SGF', 'Origin_SGU', 'Origin_SHV', 'Origin_SIT', 'Origin_SJC', 'Origin_SJT', 'Origin_SJU', 'Origin_SLC', 'Origin_SMF', 'Origin_SMX', 'Origin_SNA', 'Origin_SPS', 'Origin_SRQ', 'Origin_STL', 'Origin_STT', 'Origin_STX', 'Origin_SUN', 'Origin_SWF', 'Origin_SYR', 'Origin_TLH', 'Origin_TOL', 'Origin_TPA', 'Origin_TRI', 'Origin_TUL', 'Origin_TUS', 'Origin_TVC', 'Origin_TWF', 'Origin_TXK', 'Origin_TYR', 'Origin_TYS', 'Origin_VCT', 'Origin_VIS', 'Origin_VLD', 'Origin_VPS', 'Origin_WRG', 'Origin_WYS', 'Origin_XNA', 'Origin_YAK', 'Origin_YUM', 'Dest_ABE', 'Dest_ABI', 'Dest_ABQ', 'Dest_ABY', 'Dest_ACK', 'Dest_ACT', 'Dest_ACV', 'Dest_ACY', 'Dest_ADK', 'Dest_ADQ', 'Dest_AEX', 'Dest_AGS', 'Dest_AKN', 'Dest_ALB', 'Dest_AMA', 'Dest_ANC', 'Dest_APF', 'Dest_ATL', 'Dest_ATW', 'Dest_AUS', 'Dest_AVL', 'Dest_AVP', 'Dest_AZO', 'Dest_BDL', 'Dest_BET', 'Dest_BFL', 'Dest_BGM', 'Dest_BGR', 'Dest_BHM', 'Dest_BIL', 'Dest_BIS', 'Dest_BMI', 'Dest_BNA', 'Dest_BOI', 'Dest_BOS', 'Dest_BPT', 'Dest_BQK', 'Dest_BQN', 'Dest_BRO', 'Dest_BRW', 'Dest_BTM', 'Dest_BTR', 'Dest_BTV', 'Dest_BUF', 'Dest_BUR', 'Dest_BWI', 'Dest_BZN', 'Dest_CAE', 'Dest_CAK', 'Dest_CBM', 'Dest_CDC', 'Dest_CDV', 'Dest_CEC', 'Dest_CHA', 'Dest_CHO', 'Dest_CHS', 'Dest_CIC', 'Dest_CID', 'Dest_CKB', 'Dest_CLD', 'Dest_CLE', 'Dest_CLL', 'Dest_CLT', 'Dest_CMH', 'Dest_CMI', 'Dest_COD', 'Dest_COS', 'Dest_CPR', 'Dest_CRP', 'Dest_CRW', 'Dest_CSG', 'Dest_CVG', 'Dest_CYS', 'Dest_DAB', 'Dest_DAL', 'Dest_DAY', 'Dest_DBQ', 'Dest_DCA', 'Dest_DEN', 'Dest_DFW', 'Dest_DHN', 'Dest_DLG', 'Dest_DLH', 'Dest_DRO', 'Dest_DSM', 'Dest_DTW', 'Dest_DUT', 'Dest_EFD', 'Dest_EGE', 'Dest_EKO', 'Dest_ELP', 'Dest_ERI', 'Dest_EUG', 'Dest_EVV', 'Dest_EWR', 'Dest_EYW', 'Dest_FAI', 'Dest_FAR', 'Dest_FAT', 'Dest_FAY', 'Dest_FCA', 'Dest_FLL', 'Dest_FLO', 'Dest_FMN', 'Dest_FNT', 'Dest_FSD', 'Dest_FSM', 'Dest_FWA', 'Dest_GEG', 'Dest_GFK', 'Dest_GGG', 'Dest_GJT', 'Dest_GNV', 'Dest_GPT', 'Dest_GRB', 'Dest_GRK', 'Dest_GRR', 'Dest_GSO', 'Dest_GSP', 'Dest_GST', 'Dest_GTF', 'Dest_GTR', 'Dest_GUC', 'Dest_HDN', 'Dest_HLN', 'Dest_HNL', 'Dest_HOU', 'Dest_HPN', 'Dest_HRL', 'Dest_HSV', 'Dest_HTS', 'Dest_HVN', 'Dest_IAD', 'Dest_IAH', 'Dest_ICT', 'Dest_IDA', 'Dest_ILE', 'Dest_ILM', 'Dest_IND', 'Dest_IPL', 'Dest_ISP', 'Dest_ITO', 'Dest_IYK', 'Dest_JAC', 'Dest_JAN', 'Dest_JAX', 'Dest_JFK', 'Dest_JNU', 'Dest_KOA', 'Dest_KTN', 'Dest_LAN', 'Dest_LAS', 'Dest_LAW', 'Dest_LAX', 'Dest_LBB', 'Dest_LCH', 'Dest_LEX', 'Dest_LFT', 'Dest_LGA', 'Dest_LGB', 'Dest_LIH', 'Dest_LIT', 'Dest_LNK', 'Dest_LNY', 'Dest_LRD', 'Dest_LSE', 'Dest_LWB', 'Dest_LWS', 'Dest_LYH', 'Dest_MAF', 'Dest_MBS', 'Dest_MCI', 'Dest_MCN', 'Dest_MCO', 'Dest_MDT', 'Dest_MDW', 'Dest_MEI', 'Dest_MEM', 'Dest_MFE', 'Dest_MFR', 'Dest_MGM', 'Dest_MHT', 'Dest_MIA', 'Dest_MKE', 'Dest_MKK', 'Dest_MLB', 'Dest_MLI', 'Dest_MLU', 'Dest_MOB', 'Dest_MOD', 'Dest_MOT', 'Dest_MQT', 'Dest_MRY', 'Dest_MSN', 'Dest_MSO', 'Dest_MSP', 'Dest_MSY', 'Dest_MTJ', 'Dest_MYR', 'Dest_OAK', 'Dest_OGD', 'Dest_OGG', 'Dest_OKC', 'Dest_OMA', 'Dest_OME', 'Dest_ONT', 'Dest_ORD', 'Dest_ORF', 'Dest_OTZ', 'Dest_OXR', 'Dest_PBI', 'Dest_PDX', 'Dest_PFN', 'Dest_PHF', 'Dest_PHL', 'Dest_PHX', 'Dest_PIA', 'Dest_PIE', 'Dest_PIH', 'Dest_PIT', 'Dest_PNS', 'Dest_PSC', 'Dest_PSG', 'Dest_PSP', 'Dest_PUB', 'Dest_PVD', 'Dest_PVU', 'Dest_PWM', 'Dest_RAP', 'Dest_RDD', 'Dest_RDM', 'Dest_RDU', 'Dest_RIC', 'Dest_RNO', 'Dest_ROA', 'Dest_ROC', 'Dest_RST', 'Dest_RSW', 'Dest_SAN', 'Dest_SAT', 'Dest_SAV', 'Dest_SBA', 'Dest_SBN', 'Dest_SBP', 'Dest_SCC', 'Dest_SCE', 'Dest_SDF', 'Dest_SEA', 'Dest_SFO', 'Dest_SGF', 'Dest_SGU', 'Dest_SHV', 'Dest_SIT', 'Dest_SJC', 'Dest_SJT', 'Dest_SJU', 'Dest_SKA', 'Dest_SLC', 'Dest_SMF', 'Dest_SMX', 'Dest_SNA', 'Dest_SPS', 'Dest_SRQ', 'Dest_STL', 'Dest_STT', 'Dest_STX', 'Dest_SUN', 'Dest_SUX', 'Dest_SWF', 'Dest_SYR', 'Dest_TLH', 'Dest_TOL', 'Dest_TPA', 'Dest_TRI', 'Dest_TUL', 'Dest_TUS', 'Dest_TVC', 'Dest_TWF', 'Dest_TXK', 'Dest_TYR', 'Dest_TYS', 'Dest_VCT', 'Dest_VIS', 'Dest_VLD', 'Dest_VPS', 'Dest_WRG', 'Dest_WYS', 'Dest_XNA', 'Dest_YAK', 'Dest_YUM', 'CancellationCode_0', 'CancellationCode_A', 'CancellationCode_B', 'CancellationCode_C', 'CancellationCode_D']\n",
      "[dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('float64'), dtype('int64'), dtype('float64'), dtype('int64'), dtype('int64'), dtype('float64'), dtype('int64'), dtype('float64'), dtype('float64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool')]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "改进：（1）舍弃了不必要的分类数据TailNum和24H（这个只是在后面作为对比的列），使得我们能够正确选取训练集X的特征\n",
    "（2）在上面的模型中，不知道为什么Unique等分类列没有在get-dummies下变成独热编码的函数。这里在训练集中重新对其进行\n",
    "了独特编码，使得模型能正确进入到随机森林模型当中。\n",
    "\n",
    "\n",
    "问题：（1）在解决了特征选取等一系列问题之后，随机森林模型根本无法进行训练，并不清楚是模型本身的性能问题/计算机性能的问题，还是\n",
    "数据处理的问题\n",
    "'''\n",
    "\n",
    "\n",
    "# print(cleaned_combined_flight_data.dtypes)\n",
    "\n",
    "X = cleaned_combined_flight_data[features]\n",
    "X=X.drop(columns=['TailNum','24HoursTime'])\n",
    "# print(X.head())\n",
    "print(X.columns.tolist())\n",
    "# for col in X.select_dtypes(include=['category']).columns:\n",
    "#     X[col]=pd.get_dummies(X,columns=[col])\n",
    "X = pd.get_dummies(X, columns=['UniqueCarrier', 'Origin', 'Dest','CancellationCode'])\n",
    "print(X.columns.tolist())\n",
    "print(X.dtypes.tolist())\n",
    "#尝试在这里将Unique等三列转换为独热编码？\n",
    "y = cleaned_combined_flight_data[target]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "#目前挺进到这里的数据转型和处理阶段\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Save the model to a pkl file for server deployment\n",
    "with open('flight_delay_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Step 5: Analysis and Visualisation\n",
    "'''\n",
    "# Best times to fly to minimise delays\n",
    "best_time_of_day = cleaned_combined_flight_data.groupby(\"24HoursTime\")[\"DepDelay\"].sum()\n",
    "\n",
    "# Plot the variation of delay time at different times of the day\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(best_time_of_day, marker=\"o\")\n",
    "plt.title(\"Variation of Delay Time at Different Times of the Day\", fontsize=18)\n",
    "plt.xlabel(\"Time of the Day\", fontsize=15)\n",
    "plt.ylabel(\"Total Delay Minutes\", fontsize=15)\n",
    "plt.ticklabel_format(style=\"plain\", axis=\"y\")\n",
    "plt.show()\n",
    "\n",
    "# Best day of the week to avoid delays\n",
    "best_day_of_week = cleaned_combined_flight_data.groupby(\"DayOfWeek\")[\"DepDelay\"].sum()\n",
    "\n",
    "# Plot the variation of delay time for different days in a week\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(best_day_of_week, color=\"green\", marker=\"o\")\n",
    "plt.title(\"Variation of Delay Time for Different Days in a Week\", fontsize=18)\n",
    "plt.xlabel(\"Day of the Week\", fontsize=15)\n",
    "plt.ylabel(\"Total Delay Minutes\", fontsize=15)\n",
    "plt.ticklabel_format(style=\"plain\", axis=\"y\")\n",
    "days = [1, 2, 3, 4, 5, 6, 7]\n",
    "days_name = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "ax = plt.subplot()\n",
    "ax.set_xticks(days)\n",
    "ax.set_xticklabels(days_name, fontsize=13)\n",
    "plt.show()\n",
    "\n",
    "# Best day of the month to avoid delays\n",
    "best_day_of_month = cleaned_combined_flight_data.groupby(\"DayofMonth\")[\"DepDelay\"].sum()\n",
    "\n",
    "# Plot the variation of delay time for different days of the month\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(best_day_of_month, color=\"green\", marker=\"o\")\n",
    "plt.title(\"Variation of Delay Time for Different Days of the Month\", fontsize=18)\n",
    "plt.xlabel(\"Day of the Month\", fontsize=15)\n",
    "plt.ylabel(\"Total Delay Minutes\", fontsize=15)\n",
    "plt.ticklabel_format(style=\"plain\", axis=\"y\")\n",
    "days_of_month = range(1, 32)\n",
    "ax = plt.subplot()\n",
    "ax.set_xticks(days_of_month)\n",
    "plt.show()\n",
    "\n",
    "# Best month of the year to avoid delays\n",
    "best_month_of_year = cleaned_combined_flight_data.groupby(\"Month\")[\"DepDelay\"].sum()\n",
    "\n",
    "# Plot the variation of delay time for different months in a year\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(best_month_of_year, color=\"green\", marker=\"o\")\n",
    "plt.title(\"Variation of Delay Time for Different Months in a Year\", fontsize=18)\n",
    "plt.xlabel(\"Months of the Year\", fontsize=15)\n",
    "plt.ylabel(\"Total Delay Minutes\", fontsize=15)\n",
    "plt.ticklabel_format(style=\"plain\", axis=\"y\")\n",
    "month_names = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "months = range(1, 13)\n",
    "ax = plt.subplot()\n",
    "ax.set_xticks(months)\n",
    "ax.set_xticklabels(month_names, fontsize=13)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "Step 6: Correlation Analysis\n",
    "'''\n",
    "# Correlation between aircraft age and delays\n",
    "airlines = pd.concat(map(pd.read_csv, ['2004.csv', '2005.csv']))\n",
    "airports = pd.read_csv('airports.csv')\n",
    "planes = pd.read_csv('plane-data.csv')\n",
    "\n",
    "# Clean and preprocess data\n",
    "airlines = airlines.dropna(subset=['TailNum'])\n",
    "planes = planes.dropna(subset=['year'])\n",
    "planes = planes.rename(columns={'year': 'ManufactureYear'})\n",
    "airlines = airlines.merge(planes[['tailnum', 'ManufactureYear']], left_on='TailNum', right_on='tailnum', how='left')\n",
    "\n",
    "# Create delay indicator\n",
    "airlines['ADelay'] = np.where(airlines['ArrDelay'] > 0, 1, 0)\n",
    "\n",
    "# Group by manufacture year and delay\n",
    "df_planes_grouped = airlines.groupby(['ManufactureYear', 'ADelay']).size().reset_index(name='Counts')\n",
    "df_planes_grouped['TotalFlights'] = airlines.groupby('ManufactureYear').size().values\n",
    "df_planes_grouped['DelayPercentage'] = (df_planes_grouped['Counts'] / df_planes_grouped['TotalFlights']) * 100\n",
    "\n",
    "# Plot delay percentage by manufacture year\n",
    "df_planes_grouped = df_planes_grouped[df_planes_grouped['ADelay'] == 1]\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(df_planes_grouped['ManufactureYear'], df_planes_grouped['DelayPercentage'], color='green', marker='o')\n",
    "plt.title('Percentage of Delays by Aircraft Age', fontsize=18)\n",
    "plt.xlabel('Year of Manufacture', fontsize=15)\n",
    "plt.ylabel('Delay Percentage', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Step 7: Integrate with Flask Application\n",
    "'''\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model\n",
    "model = pickle.load(open('flight_delay_model.pkl', 'rb'))\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    prediction = model.predict(pd.DataFrame([data]))\n",
    "    return jsonify(prediction=prediction[0])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
